{
  "2507.02699v1": {
    "title": "Control at Stake: Evaluating the Security Landscape of LLM-Driven Email Agents",
    "authors": [
      "Jiangrong Wu",
      "Yuhong Nan",
      "Jianliang Wu",
      "Zitong Yao",
      "Zibin Zheng"
    ],
    "summary": "The increasing capabilities of LLMs have led to the rapid proliferation of\nLLM agent apps, where developers enhance LLMs with access to external resources\nto support complex task execution. Among these, LLM email agent apps represent\none of the widely used categories, as email remains a critical communication\nmedium for users. LLM email agents are capable of managing and responding to\nemail using LLM-driven reasoning and autonomously executing user instructions\nvia external email APIs (e.g., send email). However, despite their growing\ndeployment and utility, the security mechanism of LLM email agent apps remains\nunderexplored. Currently, there is no comprehensive study into the potential\nsecurity risk within these agent apps and their broader implications.\n  In this paper, we conduct the first in-depth and systematic security study of\nLLM email agents. We propose the Email Agent Hijacking (EAH) attack, which\noverrides the original prompts of the email agent via external email resources,\nallowing attackers to gain control of the email agent remotely and further\nperform specific attack scenarios without user awareness.\n  To facilitate the large-scale evaluation, we propose EAHawk, a pipeline to\nevaluate the EAH attack of LLM email agent apps. By EAHawk, we performed an\nempirical study spanning 14 representative LLM agent frameworks, 63 agent apps,\n12 LLMs, and 20 email services, which led to the generation of 1,404 real-world\nemail agent instances for evaluation. Experimental results indicate that all\n1,404 instances were successfully hijacked; on average, only 2.03 attack\nattempts are required to control an email agent instance. Even worse, for some\nLLMs, the average number of attempts needed to achieve full agent control drops\nto as few as 1.23.",
    "pdf_url": "http://arxiv.org/pdf/2507.02699v1",
    "published": "2025-07-03"
  },
  "2503.19213v1": {
    "title": "A Survey of Large Language Model Agents for Question Answering",
    "authors": [
      "Murong Yue"
    ],
    "summary": "This paper surveys the development of large language model (LLM)-based agents\nfor question answering (QA). Traditional agents face significant limitations,\nincluding substantial data requirements and difficulty in generalizing to new\nenvironments. LLM-based agents address these challenges by leveraging LLMs as\ntheir core reasoning engine. These agents achieve superior QA results compared\nto traditional QA pipelines and naive LLM QA systems by enabling interaction\nwith external environments. We systematically review the design of LLM agents\nin the context of QA tasks, organizing our discussion across key stages:\nplanning, question understanding, information retrieval, and answer generation.\nAdditionally, this paper identifies ongoing challenges and explores future\nresearch directions to enhance the performance of LLM agent QA systems.",
    "pdf_url": "http://arxiv.org/pdf/2503.19213v1",
    "published": "2025-03-24"
  }
}